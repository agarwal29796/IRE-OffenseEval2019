{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_C.ipynb","provenance":[{"file_id":"1aXL1Ms0-pQtfB6m2GyjXKQa1twcFWZb1","timestamp":1573361768247},{"file_id":"1htiIQd1-fbh8OTc-v9EzHa2lsHrWhJ_t","timestamp":1573359248790}],"collapsed_sections":["0jKaaJfRJumc"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zjGkTUTaFLwp","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import string\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import MaxAbsScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import GridSearchCV\n","from sklearn import preprocessing\n","from sklearn.metrics import confusion_matrix\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import LinearSVC\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import KFold\n","from keras.utils.np_utils import to_categorical\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import f1_score\n","\n","from tqdm import tqdm\n","\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import classification_report\n","# from gensim.models import Word2Vec\n","# from gensim.models import KeyedVectors\n","import pickle\n","\n","import os\n","\n","from collections import Counter\n","from scipy.sparse import hstack\n","\n","from prettytable import PrettyTable\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kyb3lV88HQ80","colab_type":"code","outputId":"21ba79b8-2fff-4529-e90c-2d6064d7f61f","executionInfo":{"status":"ok","timestamp":1573467930326,"user_tz":-330,"elapsed":1180,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","root_path = '/content/gdrive/My Drive/IRE_Major_Project/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i-NH3SX9FXE9","colab_type":"code","colab":{}},"source":["data = pd.read_csv(root_path+'preprocessed.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JkPgCn9mHngE","colab_type":"code","outputId":"12bddaf4-5ff3-472c-f6a6-84451596a3c2","executionInfo":{"status":"ok","timestamp":1573467931069,"user_tz":-330,"elapsed":1599,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":581}},"source":["data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>new_tweet</th>\n","      <th>user_mentions</th>\n","      <th>n_hash_tags</th>\n","      <th>n_urls</th>\n","      <th>n_emojis</th>\n","      <th>subtask_a</th>\n","      <th>subtask_b</th>\n","      <th>subtask_c</th>\n","      <th>new_tweet_length</th>\n","      <th>original_tweet_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>86426</td>\n","      <td>@USER She should ask a few native Americans wh...</td>\n","      <td>ask native americans take be</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>OFF</td>\n","      <td>UNT</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>90194</td>\n","      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n","      <td>go home drink maga trump2020</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>OFF</td>\n","      <td>TIN</td>\n","      <td>IND</td>\n","      <td>5</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>16820</td>\n","      <td>Amazon is investigating Chinese employees who ...</td>\n","      <td>amazon investigate chinese employees sell inte...</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>NOT</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>19</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>62688</td>\n","      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n","      <td>someone should vetaken piece shit volcano</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>OFF</td>\n","      <td>UNT</td>\n","      <td>NaN</td>\n","      <td>6</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>43605</td>\n","      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n","      <td>obama want liberals amp illegals move red state</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NOT</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>8</td>\n","      <td>12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  ... original_tweet_length\n","0  86426  ...                    14\n","1  90194  ...                    11\n","2  16820  ...                    27\n","3  62688  ...                    11\n","4  43605  ...                    12\n","\n","[5 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"6XsMzgaxB6Wm","colab_type":"text"},"source":["Dropping subtask a and b columns"]},{"cell_type":"code","metadata":{"id":"SokBxvTxkN3E","colab_type":"code","outputId":"35d5fcc7-20d7-4203-b092-796be275cefe","executionInfo":{"status":"ok","timestamp":1573467931681,"user_tz":-330,"elapsed":1845,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["data = data[data['subtask_c'].isin(['IND'  , 'GRP' , 'OTH'])]\n","data.drop(columns=['subtask_a' , 'subtask_b'] , inplace = True)\n","data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>new_tweet</th>\n","      <th>user_mentions</th>\n","      <th>n_hash_tags</th>\n","      <th>n_urls</th>\n","      <th>n_emojis</th>\n","      <th>subtask_c</th>\n","      <th>new_tweet_length</th>\n","      <th>original_tweet_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>90194</td>\n","      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n","      <td>go home drink maga trump2020</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>IND</td>\n","      <td>5</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>97670</td>\n","      <td>@USER Liberals are all Kookoo !!!</td>\n","      <td>liberals kookoo</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>OTH</td>\n","      <td>2</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>52415</td>\n","      <td>@USER was literally just talking about this lo...</td>\n","      <td>literally talk lol mass shoot like set up prop...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>GRP</td>\n","      <td>18</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>13384</td>\n","      <td>@USER Canada doesn’t need another CUCK! We alr...</td>\n","      <td>canada not need another cuck already enough lo...</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>IND</td>\n","      <td>15</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>28414</td>\n","      <td>@USER you are a lying corrupt traitor!!! Nobod...</td>\n","      <td>lie corrupt traitor nobody want hear anymore l...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>IND</td>\n","      <td>9</td>\n","      <td>17</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id  ... original_tweet_length\n","1   90194  ...                    11\n","5   97670  ...                     6\n","7   52415  ...                    31\n","9   13384  ...                    19\n","12  28414  ...                    17\n","\n","[5 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"A9btd0-FuVGD","colab_type":"code","outputId":"ecef5fca-10f8-471c-8e92-522c99e0ab02","executionInfo":{"status":"ok","timestamp":1573467931682,"user_tz":-330,"elapsed":1656,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["data.loc[data['original_tweet_length'].idxmax()]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["id                                                                   29558\n","tweet                    @USER @USER @USER @USER @USER @USER @USER @USE...\n","new_tweet                even pedophiles interview tell way stop kill t...\n","user_mentions                                                           50\n","n_hash_tags                                                              0\n","n_urls                                                                   0\n","n_emojis                                                                 0\n","subtask_c                                                              GRP\n","new_tweet_length                                                        25\n","original_tweet_length                                                  101\n","Name: 2397, dtype: object"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"Tfw2Eykouh-B","colab_type":"code","outputId":"0b7ed048-6a4d-41b1-cd53-9f8bcfbb55f0","executionInfo":{"status":"ok","timestamp":1573467931686,"user_tz":-330,"elapsed":1529,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["data.loc[data['new_tweet_length'].idxmax()]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["id                                                                   78296\n","tweet                    #NoToKavanaugh  He'll REVERSE Roe vs Wade-wome...\n","new_tweet                notokavanaugh he ll reverse roe vs wade women ...\n","user_mentions                                                            0\n","n_hash_tags                                                              1\n","n_urls                                                                   1\n","n_emojis                                                                 0\n","subtask_c                                                              GRP\n","new_tweet_length                                                        44\n","original_tweet_length                                                   38\n","Name: 11784, dtype: object"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"b_yf8Jzrx0Yo","colab_type":"text"},"source":["# Splitting Data: Train and Test\n"]},{"cell_type":"code","metadata":{"id":"df_vlf3_x5Ac","colab_type":"code","outputId":"0d73f94a-6ca7-4d73-923e-f7d4f36fe3a9","executionInfo":{"status":"ok","timestamp":1573467931687,"user_tz":-330,"elapsed":1224,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["Y = data['subtask_c']\n","X = data.drop(['subtask_c','id'],axis=1)\n","print(\"Shape of X: \",X.shape)\n","print(\"Shape of Y: \",Y.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Shape of X:  (3876, 8)\n","Shape of Y:  (3876,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-wC1MiOryP9z","colab_type":"code","outputId":"545236e5-4890-4420-8303-b5aa0cb3fb1d","executionInfo":{"status":"ok","timestamp":1573467931688,"user_tz":-330,"elapsed":1085,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["data['subtask_c'].value_counts()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["IND    2407\n","GRP    1074\n","OTH     395\n","Name: subtask_c, dtype: int64"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"ZvfvXPtG0kiE","colab_type":"code","outputId":"55761c67-4732-41c0-8e4a-ef60084eb4b2","executionInfo":{"status":"ok","timestamp":1573467931689,"user_tz":-330,"elapsed":911,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["#separating data into train and test\n","X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.30,stratify=Y, random_state=42)\n","print(\"Shape of X_train: \", X_train.shape)\n","print(\"Shape of Y_train: \",Y_train.shape)\n","print(\"Shape of X_test: \",X_test.shape)\n","print(\"Shape of Y_test: \",Y_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Shape of X_train:  (2713, 8)\n","Shape of Y_train:  (2713,)\n","Shape of X_test:  (1163, 8)\n","Shape of Y_test:  (1163,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B9wUVS59GHb6","colab_type":"text"},"source":["#### Change the mapping of the label column to binary\n"]},{"cell_type":"code","metadata":{"id":"DCGIj0WKFToi","colab_type":"code","colab":{}},"source":["Y_train = Y_train.map(dict(IND=0, GRP=1 , OTH= 2))\n","Y_test = Y_test.map(dict(IND=0, GRP=1 , OTH = 2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I5BIuG8vK5Uq","colab_type":"code","colab":{}},"source":["# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n","#     print(X_train.isnull())\n","#  X_train[X_train.isna().any(axis=1)]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xjrCkgo0j4yC","colab_type":"text"},"source":["# Convolution Model"]},{"cell_type":"code","metadata":{"id":"tjBDKSO9j_CI","colab_type":"code","colab":{}},"source":["from keras.models import Model\n","from keras.optimizers import SGD, Adam\n","from keras.layers import Input, Dense, Dropout, Flatten, Lambda, Embedding\n","from keras.layers.convolutional import Convolution1D, MaxPooling1D\n","from keras.initializers import RandomNormal\n","from keras.engine import Layer, InputSpec\n","from keras import backend as K\n","K.tensorflow_backend.set_image_dim_ordering('th')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GKgmZMCRkHzZ","colab_type":"text"},"source":["## Evaluation Metrics"]},{"cell_type":"code","metadata":{"id":"JGt_AxmckGU5","colab_type":"code","colab":{}},"source":["def recall_m(y_true, y_pred):  \n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","def precision_m(y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","def f_m(y_true, y_pred):\n","    tmp = precision_recall_fscore_support(y_true , y_pred)\n","    return tmp[2][1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0jKaaJfRJumc","colab_type":"text"},"source":["## create model"]},{"cell_type":"code","metadata":{"id":"4xZRQHuliEOs","colab_type":"code","colab":{}},"source":["def create_model(filter_kernels, dense_outputs, maxlen, vocab_size, nb_filter, cat_output):\n","    initializer = RandomNormal(mean=0.0, stddev=0.05, seed=None)\n","\n","    # Define what the input shape looks like\n","    inputs = Input(shape=(maxlen,), dtype='int64')\n","    print('inputs shape: ',inputs.shape)\n","    a_func = 'relu'\n","    import tensorflow as tf\n","\n","    def one_hot(x):\n","        return tf.one_hot(x, vocab_size, on_value=1.0, off_value=0.0, axis=-1, dtype=tf.float32)\n","\n","    def one_hot_outshape(in_shape):\n","        return in_shape[0], in_shape[1], vocab_size\n","\n","    embedded = Lambda(one_hot, output_shape=one_hot_outshape)(inputs)\n","\n","    # All the convolutional layers...\n","    conv = Convolution1D(filters=nb_filter, kernel_size=filter_kernels[0], kernel_initializer=initializer, #7\n","                         padding='valid', activation = a_func,\n","                         input_shape=(maxlen, vocab_size), name='Conv1')(embedded)\n","    print('conv shape: ',conv.shape)\n","    conv = MaxPooling1D(pool_size=2, strides = 2, name='MaxPool1')(conv)\n","    print('conv max pool shape: ',conv.shape)\n","\n","    conv1 = Convolution1D(filters=nb_filter, kernel_size=filter_kernels[1], kernel_initializer=initializer, #5\n","                          padding='valid', activation=a_func, name='Conv2')(conv)\n","    print('conv1 shape: ',conv1.shape)\n","\n","    # conv1 = MaxPooling1D(pool_size=2, name='MaxPool2')(conv1)\n","    # print('conv1 m.p shape: ',conv1.shape)\n","\n","    conv2 = Convolution1D(filters=nb_filter, kernel_size=filter_kernels[2], kernel_initializer=initializer, #3\n","                          padding='valid', activation=a_func, name='Conv3')(conv1)\n","    print('conv2 shape: ',conv2.shape)\n","    # conv2 = MaxPooling1D(pool_size=2, strides = 2, name='MaxPool3')(conv2)\n","    # print('conv2 m.p shape: ',conv2.shape)\n","\n","    conv3 = Convolution1D(filters=nb_filter, kernel_size=filter_kernels[3], kernel_initializer=initializer, #2\n","                          padding='valid', activation=a_func, name='Conv4')(conv2) \n","    print('conv3 shape: ',conv3.shape)\n","\n","    conv4 = Convolution1D(filters=nb_filter, kernel_size=filter_kernels[4], kernel_initializer=initializer,\n","                          padding='valid', activation=a_func, name='Conv5')(conv3)\n","    print('conv4 shape: ',conv4.shape)\n","\n","    conv5 = Convolution1D(filters=nb_filter, kernel_size=filter_kernels[5], kernel_initializer=initializer,\n","                          padding='valid', activation=a_func,  name='Conv6')(conv4)\n","    print('conv5 shape: ',conv5.shape)\n","\n","    conv5 = MaxPooling1D(pool_size=3, strides = 2, name='MaxPool4')(conv3)\n","    print('conv5 m.p shape: ',conv5.shape)\n","\n","    # k = 40\n","    # # K-max pooling\n","    # def kmax_outshape(in_shape):\n","    #     return (in_shape[0], in_shape[2]*k)\n","    # def KMaxPooling(inputs):        \n","    #     # swap last two dimensions since top_k will be applied along the last dimension\n","    #     shifted_input = tf.transpose(inputs, [0, 2, 1])\n","    #     # extract top_k, returns two tensors [values, indices]\n","    #     top_k = tf.nn.top_k(shifted_input, k=k, sorted=True, name='TopK')[0]\n","    #     return top_k\n","\n","    # conv5 = Lambda(KMaxPooling, output_shape=kmax_outshape)(conv5)\n","    conv5 = Flatten()(conv5)\n","    print('conv5 flatten shape: ',conv5.shape)\n","\n","    # Two dense layers with dropout of .5\n","    z = Dropout(0.2)(Dense(dense_outputs, activation='relu')(conv5))\n","    z = Dropout(0.2)(Dense(dense_outputs, activation='relu')(z))\n","\n","    # Output dense layer with softmax activation\n","    pred = Dense(cat_output, activation='softmax', name='output')(z)\n","\n","    model = Model(inputs=inputs, outputs=pred)\n","    print(model.summary())\n","    sgd = SGD(lr=0.01, momentum=0.9)\n","    adam = Adam(lr=0.001)  # Feel free to use SGD above. I found Adam with lr=0.001 is faster than SGD with lr=0.01\n","    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy', f1_m ,precision_m, recall_m])\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"krnQBIu6xUyn","colab_type":"text"},"source":["## Making Data Model Ready: Encoding Tweets"]},{"cell_type":"markdown","metadata":{"id":"Ba4weCmHlNgw","colab_type":"text"},"source":["### Quantization  "]},{"cell_type":"code","metadata":{"id":"basXFKCelM4e","colab_type":"code","colab":{}},"source":["def encode_data(x, maxlen, vocab):\n","    # Iterate over the loaded data and create a matrix of size (len(x), maxlen)\n","    # Each character is encoded into a one-hot array later at the lambda layer.\n","    # Chars not in the vocab are encoded as -1, into an all zero vector.\n","    \n","    input_data = np.zeros((len(x), maxlen), dtype=np.int)\n","    for dix, sent in enumerate(x):\n","        counter = 0\n","        for c in sent:\n","            if counter >= maxlen:\n","                pass\n","            else:\n","                ix = vocab.get(c, -1)  # get index from vocab dictionary, if not in vocab, return -1\n","                input_data[dix, counter] = ix\n","                counter += 1\n","    return input_data\n","\n","\n","def create_vocab_set():\n","    # This alphabet is 69 chars vs. 70 reported in the paper since they include two\n","    # '-' characters. See https://github.com/zhangxiangxiao/Crepe#issues.\n","\n","    alphabet = set(list(string.ascii_lowercase) + list(string.digits) +\n","                   list(string.punctuation) + ['\\n'])\n","    vocab_size = len(alphabet)\n","    vocab = {}\n","    reverse_vocab = {}\n","    for ix, t in enumerate(alphabet):\n","        vocab[t] = ix\n","        reverse_vocab[ix] = t\n","\n","    return vocab, reverse_vocab, vocab_size, alphabet"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMzh6vExltua","colab_type":"code","colab":{}},"source":["vocab, reverse_vocab, vocab_size, alphabet = create_vocab_set()\n","\n","# Maximum encoding length. Longer gets chopped. Shorter gets padded.\n","max_encode_len = 1200"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T6N1HpYqJzKH","colab_type":"text"},"source":["## feature sets"]},{"cell_type":"code","metadata":{"id":"XtvD_NBu92Y9","colab_type":"code","outputId":"0e223e32-9749-435e-a853-70ad82fcc4cf","executionInfo":{"status":"ok","timestamp":1573467938209,"user_tz":-330,"elapsed":995,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["f1 = encode_data(X_train['new_tweet'], max_encode_len, vocab)\n","f2 = X_train['user_mentions'].values.reshape(-1,1)\n","f3 = X_train['n_hash_tags'].values.reshape(-1,1)\n","f4 = X_train['n_urls'].values.reshape(-1,1)\n","# f5 = X_train['n_emojis'].values.reshape(-1,1)\n","f6 = X_train['new_tweet_length'].values.reshape(-1,1)\n","# f7 = X_train['original_tweet_length'].values.reshape(-1,1)\n","\n","# X_train_bow = np.concatenate((f1 , f2 , f3 , f4 , f5 , f6 , f7 ) , axis = 1)\n","X_train_bow = np.concatenate((f1 , f2 , f3 , f4 , f6 ) , axis = 1)\n","\n","print(X_train_bow.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2713, 1204)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QYVZGRQQ9ukb","colab_type":"code","outputId":"cd6e937c-931f-42c0-85fb-e0324210924b","executionInfo":{"status":"ok","timestamp":1573467938690,"user_tz":-330,"elapsed":542,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["f1 = encode_data(X_test['new_tweet'], max_encode_len, vocab)\n","f2 = X_test['user_mentions'].values.reshape(-1,1)\n","f3 = X_test['n_hash_tags'].values.reshape(-1,1)\n","f4 = X_test['n_urls'].values.reshape(-1,1)\n","f5 = X_test['n_emojis'].values.reshape(-1,1)\n","f6 = X_test['new_tweet_length'].values.reshape(-1,1)\n","f7 = X_test['original_tweet_length'].values.reshape(-1,1)\n","\n","# X_test_bow = np.concatenate((f1 , f2 , f3 , f4 , f5 , f6 , f7 ) , axis = 1)\n","X_test_bow = np.concatenate((f1 , f2 , f3 , f4 , f6 ) , axis = 1)\n","print(X_test_bow.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1163, 1204)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ytJRLhUu_gV8","colab_type":"code","outputId":"ad4e4d76-a35b-4391-f4ff-3d62698c6272","executionInfo":{"status":"ok","timestamp":1573467960215,"user_tz":-330,"elapsed":743,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import pandas as pd\n","from collections import Counter\n","\n","def get_class_weights(y):\n","    counter = Counter(y)\n","    majority = max(counter.values())\n","    return  {cls: round(float(majority)/float(count), 2) for cls, count in counter.items()}\n","\n","class_weight = get_class_weights(Y_train)\n","print(\"Each class samples \" , print(Y_train_cat.sum(axis = 0)))\n","print(\" Class Weights : \" , class_weight)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1685.  752.  276.]\n","Each class samples  None\n"," Class Weights :  {1: 2.24, 0: 1.0, 2: 6.11}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wmobhn0NoePU","colab_type":"code","outputId":"9efce992-88e1-4dfd-fae1-48d3a19a8b87","executionInfo":{"status":"ok","timestamp":1573467974503,"user_tz":-330,"elapsed":977,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["Y_train_cat  = to_categorical(Y_train) \n","Y_test_cat = to_categorical(Y_test)\n","\n","print(X_train_bow.shape , Y_train.shape , Y_train_cat.shape)\n","print(X_test_bow.shape , Y_test.shape ,  Y_test_cat.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2713, 1204) (2713,) (2713, 3)\n","(1163, 1204) (1163,) (1163, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bvBZ73jNkxEi","colab_type":"text"},"source":["## Training/Validation"]},{"cell_type":"markdown","metadata":{"id":"X3tHz7RwajZJ","colab_type":"text"},"source":["Using k-fold"]},{"cell_type":"code","metadata":{"id":"Ytnf6WdehNk5","colab_type":"code","outputId":"20bba5a4-4f1e-45ec-d0f0-9aaa1c71bb3f","executionInfo":{"status":"ok","timestamp":1573468073076,"user_tz":-330,"elapsed":81067,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["np.random.seed(123)  # for reproducibility\n","save = False\n","model_name_path = root_path + 'CNN/C_params/crepe_model.json'\n","model_weights_path = root_path + 'CNN/C_params/crepe_model_weights.h5'\n","# Model params\n","# Maximum encoding length. Longer gets chopped. Shorter gets padded.\n","maxlen = X_train_bow.shape[1]\n","\n","# Filters for conv layers\n","nb_filter = 32\n","\n","# Number of units in the dense layer\n","dense_outputs = 1024 #1024\n","\n","# Conv layer kernel size\n","filter_kernels =  [7, 5, 3, 2, 2, 2]\n","\n","# Number of units in the final output layer. Number of classes.\n","cat_output = 3\n","\n","# Compile/fit params\n","batch_size = X_train_bow.shape[0]//50\n","nb_epoch = 20\n","\n","alphabet = set(list(string.ascii_lowercase) + list(string.digits) + list(string.punctuation) + ['\\n'])\n","vocab_size =  len(alphabet)\n","\n","seed = 10\n","fold = 1\n","\n","kfold = StratifiedKFold(n_splits=3)\n","\n","# kfold.get_n_splits(X_train_bow)\n","cvscores = []\n","testscores = []\n","test_predictions = []\n","\n","for train, val in kfold.split(X_train_bow  , Y_train):\n","    print(\"------------------------------------------------------------------------------\")\n","    print(\"FOLD \", fold)\n","    # model = create_model([7, 7, 3, 3, 3, 3], 1024, 1020, len(alphabet), 256, 3)\n","\n","    model = create_model(filter_kernels, dense_outputs, maxlen, vocab_size, nb_filter, cat_output)\n","    model.fit( X_train_bow[train] , Y_train_cat[train] , class_weight = class_weight, batch_size=batch_size, epochs=nb_epoch, validation_split=0.0)\n","    \n","    val_score = model.evaluate( X_train_bow[val], Y_train_cat[val] , verbose=0)\n","    test_score = model.evaluate( X_test_bow , Y_test_cat , verbose=0 )\n","    temp_pred = model.predict(X_test_bow)\n","    test_predictions.append(temp_pred.argmax(axis = 1))\n","    \n","    print(\"\\n =====   Fold ==== \" ,  fold , \" val score : \" , val_score[1])\n","    \n","    cvscores.append(val_score[1]*100)\n","    testscores.append(test_score[1]*100)\n","\n","    fold += 1\n","\n","print(\"------------------------------------------------------------------------------\")\n","print(\"Validation Accuracy : %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n","print(\"Test Accuracy : %.2f%% (+/- %.2f%%)\" % (np.mean(testscores), np.std(testscores)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["------------------------------------------------------------------------------\n","FOLD  1\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","inputs shape:  (?, 1204)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n","\n","conv shape:  (?, 1198, 32)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","conv max pool shape:  (?, 599, 32)\n","conv1 shape:  (?, 595, 32)\n","conv2 shape:  (?, 593, 32)\n","conv3 shape:  (?, 592, 32)\n","conv4 shape:  (?, 591, 32)\n","conv5 shape:  (?, 590, 32)\n","conv5 m.p shape:  (?, 295, 32)\n","conv5 flatten shape:  (?, ?)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 1204)              0         \n","_________________________________________________________________\n","lambda_1 (Lambda)            (None, 1204, 69)          0         \n","_________________________________________________________________\n","Conv1 (Conv1D)               (None, 1198, 32)          15488     \n","_________________________________________________________________\n","MaxPool1 (MaxPooling1D)      (None, 599, 32)           0         \n","_________________________________________________________________\n","Conv2 (Conv1D)               (None, 595, 32)           5152      \n","_________________________________________________________________\n","Conv3 (Conv1D)               (None, 593, 32)           3104      \n","_________________________________________________________________\n","Conv4 (Conv1D)               (None, 592, 32)           2080      \n","_________________________________________________________________\n","MaxPool4 (MaxPooling1D)      (None, 295, 32)           0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 9440)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1024)              9667584   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","output (Dense)               (None, 3)                 3075      \n","=================================================================\n","Total params: 10,746,083\n","Trainable params: 10,746,083\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/20\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","1808/1808 [==============================] - 9s 5ms/step - loss: 2.0507 - acc: 0.2909 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n","Epoch 2/20\n","1808/1808 [==============================] - 1s 592us/step - loss: 2.0110 - acc: 0.5188 - f1_m: 0.0131 - precision_m: 0.1463 - recall_m: 0.0072\n","Epoch 3/20\n","1808/1808 [==============================] - 1s 586us/step - loss: 1.9985 - acc: 0.5537 - f1_m: 0.0596 - precision_m: 0.2953 - recall_m: 0.0360\n","Epoch 4/20\n","1808/1808 [==============================] - 1s 593us/step - loss: 1.9519 - acc: 0.5481 - f1_m: 0.1811 - precision_m: 0.4924 - recall_m: 0.1228\n","Epoch 5/20\n","1808/1808 [==============================] - 1s 585us/step - loss: 1.8812 - acc: 0.6327 - f1_m: 0.3584 - precision_m: 0.6805 - recall_m: 0.2716\n","Epoch 6/20\n","1808/1808 [==============================] - 1s 579us/step - loss: 1.7952 - acc: 0.6632 - f1_m: 0.5061 - precision_m: 0.7423 - recall_m: 0.4004\n","Epoch 7/20\n","1808/1808 [==============================] - 1s 583us/step - loss: 1.7563 - acc: 0.6510 - f1_m: 0.5873 - precision_m: 0.7505 - recall_m: 0.4851\n","Epoch 8/20\n","1808/1808 [==============================] - 1s 597us/step - loss: 1.6920 - acc: 0.6560 - f1_m: 0.4915 - precision_m: 0.7200 - recall_m: 0.3971\n","Epoch 9/20\n","1808/1808 [==============================] - 1s 591us/step - loss: 1.5424 - acc: 0.6869 - f1_m: 0.6332 - precision_m: 0.7520 - recall_m: 0.5514\n","Epoch 10/20\n","1808/1808 [==============================] - 1s 590us/step - loss: 1.3389 - acc: 0.7439 - f1_m: 0.7279 - precision_m: 0.7940 - recall_m: 0.6731\n","Epoch 11/20\n","1808/1808 [==============================] - 1s 596us/step - loss: 1.2481 - acc: 0.7600 - f1_m: 0.7446 - precision_m: 0.7911 - recall_m: 0.7041\n","Epoch 12/20\n","1808/1808 [==============================] - 1s 604us/step - loss: 1.0746 - acc: 0.7976 - f1_m: 0.7910 - precision_m: 0.8202 - recall_m: 0.7644\n","Epoch 13/20\n","1808/1808 [==============================] - 1s 600us/step - loss: 0.9473 - acc: 0.8186 - f1_m: 0.8140 - precision_m: 0.8308 - recall_m: 0.7981\n","Epoch 14/20\n","1808/1808 [==============================] - 1s 603us/step - loss: 0.8049 - acc: 0.8551 - f1_m: 0.8537 - precision_m: 0.8689 - recall_m: 0.8396\n","Epoch 15/20\n","1808/1808 [==============================] - 1s 601us/step - loss: 0.7162 - acc: 0.8883 - f1_m: 0.8848 - precision_m: 0.8916 - recall_m: 0.8783\n","Epoch 16/20\n","1808/1808 [==============================] - 1s 603us/step - loss: 0.6412 - acc: 0.8927 - f1_m: 0.8913 - precision_m: 0.8968 - recall_m: 0.8861\n","Epoch 17/20\n","1808/1808 [==============================] - 1s 599us/step - loss: 0.5586 - acc: 0.9132 - f1_m: 0.9109 - precision_m: 0.9189 - recall_m: 0.9032\n","Epoch 18/20\n","1808/1808 [==============================] - 1s 604us/step - loss: 0.4867 - acc: 0.9043 - f1_m: 0.9042 - precision_m: 0.9146 - recall_m: 0.8944\n","Epoch 19/20\n","1808/1808 [==============================] - 1s 602us/step - loss: 0.4159 - acc: 0.9281 - f1_m: 0.9285 - precision_m: 0.9335 - recall_m: 0.9237\n","Epoch 20/20\n","1808/1808 [==============================] - 1s 601us/step - loss: 0.3733 - acc: 0.9198 - f1_m: 0.9219 - precision_m: 0.9305 - recall_m: 0.9137\n","\n"," =====   Fold ====  1  val score :  0.4817679558340357\n","------------------------------------------------------------------------------\n","FOLD  2\n","inputs shape:  (?, 1204)\n","conv shape:  (?, 1198, 32)\n","conv max pool shape:  (?, 599, 32)\n","conv1 shape:  (?, 595, 32)\n","conv2 shape:  (?, 593, 32)\n","conv3 shape:  (?, 592, 32)\n","conv4 shape:  (?, 591, 32)\n","conv5 shape:  (?, 590, 32)\n","conv5 m.p shape:  (?, 295, 32)\n","conv5 flatten shape:  (?, ?)\n","Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 1204)              0         \n","_________________________________________________________________\n","lambda_2 (Lambda)            (None, 1204, 69)          0         \n","_________________________________________________________________\n","Conv1 (Conv1D)               (None, 1198, 32)          15488     \n","_________________________________________________________________\n","MaxPool1 (MaxPooling1D)      (None, 599, 32)           0         \n","_________________________________________________________________\n","Conv2 (Conv1D)               (None, 595, 32)           5152      \n","_________________________________________________________________\n","Conv3 (Conv1D)               (None, 593, 32)           3104      \n","_________________________________________________________________\n","Conv4 (Conv1D)               (None, 592, 32)           2080      \n","_________________________________________________________________\n","MaxPool4 (MaxPooling1D)      (None, 295, 32)           0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 9440)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1024)              9667584   \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","output (Dense)               (None, 3)                 3075      \n","=================================================================\n","Total params: 10,746,083\n","Trainable params: 10,746,083\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/20\n","1808/1808 [==============================] - 2s 1ms/step - loss: 2.0469 - acc: 0.3634 - f1_m: 0.0010 - precision_m: 0.0072 - recall_m: 5.5310e-04    \n","Epoch 2/20\n","1808/1808 [==============================] - 1s 597us/step - loss: 2.0311 - acc: 0.4287 - f1_m: 0.0088 - precision_m: 0.0213 - recall_m: 0.0055\n","Epoch 3/20\n","1808/1808 [==============================] - 1s 592us/step - loss: 2.0012 - acc: 0.5371 - f1_m: 0.1147 - precision_m: 0.2709 - recall_m: 0.0785\n","Epoch 4/20\n","1808/1808 [==============================] - 1s 596us/step - loss: 1.9795 - acc: 0.4696 - f1_m: 0.2683 - precision_m: 0.8089 - recall_m: 0.1676\n","Epoch 5/20\n","1808/1808 [==============================] - 1s 594us/step - loss: 1.9653 - acc: 0.5664 - f1_m: 0.2468 - precision_m: 0.5693 - recall_m: 0.1698\n","Epoch 6/20\n","1808/1808 [==============================] - 1s 596us/step - loss: 1.8978 - acc: 0.5841 - f1_m: 0.4561 - precision_m: 0.7621 - recall_m: 0.3390\n","Epoch 7/20\n","1808/1808 [==============================] - 1s 589us/step - loss: 1.8309 - acc: 0.6316 - f1_m: 0.5548 - precision_m: 0.7906 - recall_m: 0.4309\n","Epoch 8/20\n","1808/1808 [==============================] - 1s 596us/step - loss: 1.8472 - acc: 0.5913 - f1_m: 0.5203 - precision_m: 0.8055 - recall_m: 0.3921\n","Epoch 9/20\n","1808/1808 [==============================] - 1s 594us/step - loss: 1.7690 - acc: 0.6355 - f1_m: 0.5700 - precision_m: 0.8113 - recall_m: 0.4497\n","Epoch 10/20\n","1808/1808 [==============================] - 1s 590us/step - loss: 1.6801 - acc: 0.6698 - f1_m: 0.6385 - precision_m: 0.8225 - recall_m: 0.5243\n","Epoch 11/20\n","1808/1808 [==============================] - 1s 590us/step - loss: 1.5700 - acc: 0.6692 - f1_m: 0.6617 - precision_m: 0.7865 - recall_m: 0.5741\n","Epoch 12/20\n","1808/1808 [==============================] - 1s 589us/step - loss: 1.4136 - acc: 0.7229 - f1_m: 0.7192 - precision_m: 0.7824 - recall_m: 0.6670\n","Epoch 13/20\n","1808/1808 [==============================] - 1s 607us/step - loss: 1.3156 - acc: 0.7445 - f1_m: 0.7434 - precision_m: 0.7797 - recall_m: 0.7113\n","Epoch 14/20\n","1808/1808 [==============================] - 1s 597us/step - loss: 1.2504 - acc: 0.7400 - f1_m: 0.7396 - precision_m: 0.7625 - recall_m: 0.7185\n","Epoch 15/20\n","1808/1808 [==============================] - 1s 594us/step - loss: 1.1057 - acc: 0.7871 - f1_m: 0.7871 - precision_m: 0.8103 - recall_m: 0.7655\n","Epoch 16/20\n","1808/1808 [==============================] - 1s 591us/step - loss: 0.8747 - acc: 0.8363 - f1_m: 0.8346 - precision_m: 0.8474 - recall_m: 0.8225\n","Epoch 17/20\n","1808/1808 [==============================] - 1s 594us/step - loss: 0.8556 - acc: 0.8302 - f1_m: 0.8297 - precision_m: 0.8390 - recall_m: 0.8208\n","Epoch 18/20\n","1808/1808 [==============================] - 1s 593us/step - loss: 0.7509 - acc: 0.8667 - f1_m: 0.8660 - precision_m: 0.8791 - recall_m: 0.8534\n","Epoch 19/20\n","1808/1808 [==============================] - 1s 592us/step - loss: 0.7273 - acc: 0.8678 - f1_m: 0.8667 - precision_m: 0.8752 - recall_m: 0.8584\n","Epoch 20/20\n","1808/1808 [==============================] - 1s 592us/step - loss: 0.6355 - acc: 0.8794 - f1_m: 0.8776 - precision_m: 0.8827 - recall_m: 0.8728\n","\n"," =====   Fold ====  2  val score :  0.572375690706527\n","------------------------------------------------------------------------------\n","FOLD  3\n","inputs shape:  (?, 1204)\n","conv shape:  (?, 1198, 32)\n","conv max pool shape:  (?, 599, 32)\n","conv1 shape:  (?, 595, 32)\n","conv2 shape:  (?, 593, 32)\n","conv3 shape:  (?, 592, 32)\n","conv4 shape:  (?, 591, 32)\n","conv5 shape:  (?, 590, 32)\n","conv5 m.p shape:  (?, 295, 32)\n","conv5 flatten shape:  (?, ?)\n","Model: \"model_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 1204)              0         \n","_________________________________________________________________\n","lambda_3 (Lambda)            (None, 1204, 69)          0         \n","_________________________________________________________________\n","Conv1 (Conv1D)               (None, 1198, 32)          15488     \n","_________________________________________________________________\n","MaxPool1 (MaxPooling1D)      (None, 599, 32)           0         \n","_________________________________________________________________\n","Conv2 (Conv1D)               (None, 595, 32)           5152      \n","_________________________________________________________________\n","Conv3 (Conv1D)               (None, 593, 32)           3104      \n","_________________________________________________________________\n","Conv4 (Conv1D)               (None, 592, 32)           2080      \n","_________________________________________________________________\n","MaxPool4 (MaxPooling1D)      (None, 295, 32)           0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 9440)              0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1024)              9667584   \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","output (Dense)               (None, 3)                 3075      \n","=================================================================\n","Total params: 10,746,083\n","Trainable params: 10,746,083\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/20\n","1810/1810 [==============================] - 2s 1ms/step - loss: 2.0467 - acc: 0.2398 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n","Epoch 2/20\n","1810/1810 [==============================] - 1s 601us/step - loss: 2.0074 - acc: 0.5387 - f1_m: 0.0724 - precision_m: 0.3443 - recall_m: 0.0470\n","Epoch 3/20\n","1810/1810 [==============================] - 1s 602us/step - loss: 1.9726 - acc: 0.5464 - f1_m: 0.0962 - precision_m: 0.3628 - recall_m: 0.0624\n","Epoch 4/20\n","1810/1810 [==============================] - 1s 593us/step - loss: 1.9024 - acc: 0.6028 - f1_m: 0.2639 - precision_m: 0.6471 - recall_m: 0.1762\n","Epoch 5/20\n","1810/1810 [==============================] - 1s 608us/step - loss: 1.7960 - acc: 0.6293 - f1_m: 0.5307 - precision_m: 0.7734 - recall_m: 0.4088\n","Epoch 6/20\n","1810/1810 [==============================] - 1s 591us/step - loss: 1.7310 - acc: 0.6514 - f1_m: 0.5210 - precision_m: 0.7902 - recall_m: 0.4066\n","Epoch 7/20\n","1810/1810 [==============================] - 1s 594us/step - loss: 1.5575 - acc: 0.6862 - f1_m: 0.6464 - precision_m: 0.7859 - recall_m: 0.5575\n","Epoch 8/20\n","1810/1810 [==============================] - 1s 599us/step - loss: 1.3460 - acc: 0.7249 - f1_m: 0.6929 - precision_m: 0.7761 - recall_m: 0.6282\n","Epoch 9/20\n","1810/1810 [==============================] - 1s 593us/step - loss: 1.1323 - acc: 0.7702 - f1_m: 0.7606 - precision_m: 0.7978 - recall_m: 0.7276\n","Epoch 10/20\n","1810/1810 [==============================] - 1s 597us/step - loss: 0.9062 - acc: 0.8033 - f1_m: 0.7957 - precision_m: 0.8191 - recall_m: 0.7740\n","Epoch 11/20\n","1810/1810 [==============================] - 1s 596us/step - loss: 0.6671 - acc: 0.8680 - f1_m: 0.8666 - precision_m: 0.8803 - recall_m: 0.8536\n","Epoch 12/20\n","1810/1810 [==============================] - 1s 593us/step - loss: 0.4671 - acc: 0.9227 - f1_m: 0.9217 - precision_m: 0.9258 - recall_m: 0.9177\n","Epoch 13/20\n","1810/1810 [==============================] - 1s 590us/step - loss: 0.4859 - acc: 0.8961 - f1_m: 0.8980 - precision_m: 0.9068 - recall_m: 0.8895\n","Epoch 14/20\n","1810/1810 [==============================] - 1s 597us/step - loss: 0.3631 - acc: 0.9298 - f1_m: 0.9312 - precision_m: 0.9349 - recall_m: 0.9276\n","Epoch 15/20\n","1810/1810 [==============================] - 1s 601us/step - loss: 0.2402 - acc: 0.9619 - f1_m: 0.9615 - precision_m: 0.9634 - recall_m: 0.9597\n","Epoch 16/20\n","1810/1810 [==============================] - 1s 602us/step - loss: 0.1842 - acc: 0.9707 - f1_m: 0.9718 - precision_m: 0.9734 - recall_m: 0.9702\n","Epoch 17/20\n","1810/1810 [==============================] - 1s 596us/step - loss: 0.2185 - acc: 0.9652 - f1_m: 0.9657 - precision_m: 0.9668 - recall_m: 0.9646\n","Epoch 18/20\n","1810/1810 [==============================] - 1s 603us/step - loss: 0.1816 - acc: 0.9691 - f1_m: 0.9698 - precision_m: 0.9722 - recall_m: 0.9674\n","Epoch 19/20\n","1810/1810 [==============================] - 1s 600us/step - loss: 0.1408 - acc: 0.9785 - f1_m: 0.9784 - precision_m: 0.9801 - recall_m: 0.9768\n","Epoch 20/20\n","1810/1810 [==============================] - 1s 593us/step - loss: 0.1239 - acc: 0.9773 - f1_m: 0.9768 - precision_m: 0.9773 - recall_m: 0.9762\n","\n"," =====   Fold ====  3  val score :  0.572535991173646\n","------------------------------------------------------------------------------\n","Validation Accuracy : 54.22% (+/- 4.28%)\n","Test Accuracy : 55.40% (+/- 3.81%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"en53n1zzJwDe","colab_type":"code","outputId":"a9b2c1f2-1726-48cd-aded-b178bd2cb03d","executionInfo":{"status":"ok","timestamp":1573468086049,"user_tz":-330,"elapsed":1203,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["# if sum is (0 or 1) -> 0(predicted class )  else (2 , 3) -> 1\n","# final_prediction = np.sum(np.array(test_predictions).T , axis = 1)//2\n","from scipy import stats\n","\n","final_prediction = stats.mode(np.array(test_predictions).T,axis=1)[0].flatten()\n","\n","# print(set(final_prediction))\n","print(classification_report(Y_test , final_prediction))\n","results = confusion_matrix(Y_test , final_prediction)\n","\n","%matplotlib inline\n","plt.figure(figsize = (5,5))\n","ax = sns.heatmap(results, cmap=\"Blues\", annot=True,annot_kws={\"size\": 14},fmt='g')\n","bottom, top = ax.get_ylim()\n","ax.set_ylim(bottom + 0.5, top - 0.5)\n","plt.title('CNN')\n","plt.ylabel('True Class')\n","plt.xlabel('Predicted Class')\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.73      0.82      0.77       722\n","           1       0.55      0.46      0.50       322\n","           2       0.17      0.11      0.13       119\n","\n","    accuracy                           0.65      1163\n","   macro avg       0.48      0.46      0.47      1163\n","weighted avg       0.62      0.65      0.63      1163\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUIAAAFNCAYAAAB1+2ZJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRJ6CUEQiT0EoIpGnIBSRyPt/yrYF718QHJkAAAAASUVORK5CYII=\n","text/plain":["<Figure size 360x360 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"0E9M30XP080E","colab_type":"code","outputId":"b64999f8-4c51-48d2-a8d4-df1c7f4de30e","executionInfo":{"status":"ok","timestamp":1573454040130,"user_tz":-330,"elapsed":1232,"user":{"displayName":"Shruti Chandra","photoUrl":"","userId":"13968414218437022561"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["f1_score(Y_test, final_prediction, average='micro')  "],"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.648323301805675"]},"metadata":{"tags":[]},"execution_count":103}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NqLUN_LCMJ9U"},"source":["### Misclassified examples for k fold"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PqSBOqQzMJ9m","colab":{}},"source":["y_test_predict_cat = final_prediction\n","y_test = np.asarray(Y_test)\n","misclassified = np.where(y_test != y_test_predict_cat)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O_9YHTARMJ94","outputId":"5668b156-3165-4bc3-d399-5d62564b3563","executionInfo":{"status":"ok","timestamp":1573452686267,"user_tz":-330,"elapsed":687,"user":{"displayName":"Shruti Chandra","photoUrl":"","userId":"13968414218437022561"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print(set(y_test))\n","print(set(y_test_predict_cat))"],"execution_count":95,"outputs":[{"output_type":"stream","text":["{0, 1, 2}\n","{0, 1, 2}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EybmG5xG7xa9","colab_type":"code","outputId":"34e0be67-6e03-48c0-bf94-f3c2060d9fc3","executionInfo":{"status":"ok","timestamp":1573468406562,"user_tz":-330,"elapsed":862,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["X_test.iloc[0,0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER now you touched visa-mata\\'s raw nerve by saying modi for 2019\" thats why she may block you soon  she is having wild/wet dream of being PM after modi fail to get full majority in 2019.  please dont wake her up from her dream of bhajpaa getting 160 seat in 2014\"'"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FDqYU_l5MJ-H","colab":{}},"source":["def prRed(skk): print(\"\\033[91m {}\\033[00m\" .format(skk)) \n","def prGreen(skk): print(\"\\033[92m {}\\033[00m\" .format(skk)) \n","def prPurple(skk): print(\"\\033[95m {}\\033[00m\" .format(skk)) \n","def prCyan(skk): print(\"\\033[96m {}\\033[00m\" .format(skk)) \n","def prLighBlue(skk): print(\"\\033[94m {}\\033[00m\" .format(skk)) \n","def prOrange(skk): print(\"\\033[33m {}\\033[00m\" .format(skk)) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"68stvH2JMJ-T"},"source":["Red: original individual insult (0), classified as group (1)<br>\n","Green: original individual insult (0), classified as other (2)<br>\n","Purple: original group insult (1), classified as individual (0) <br>\n","Cyan: original group insult (1), classified as other (2)<br>\n","Light Blue: original other insult (2), classified as individual (0) <br>\n","Orange: original other insult (2), classified as group (1)"]},{"cell_type":"code","metadata":{"id":"Nap1PqaK7lbm","colab_type":"code","colab":{}},"source":["def print_stuff(idx):\n","  global test_predictions\n","  global X_test\n","  global y_test\n","  # preprocessed_tweet\n","  print('preprocessed tweet')\n","  print(X_test.iloc[idx,1])\n","  # computed prob\n","  print('computed classes: ',np.array(test_predictions).T[idx])\n","  print('original class: ',y_test[idx] )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WrAuqrpdMJ-W","outputId":"17499c38-3f8b-4106-e1c4-effd5612510e","executionInfo":{"status":"ok","timestamp":1573452760902,"user_tz":-330,"elapsed":1258,"user":{"displayName":"Shruti Chandra","photoUrl":"","userId":"13968414218437022561"}},"colab":{"base_uri":"https://localhost:8080/","height":819}},"source":["#IND=0, GRP=1 , OTH= 2\n","c = [0] * 6\n","limit = 5\n","for index in misclassified[0]:\n","  #original individual insult (0), classified as group (1)\n","  if limit in c:\n","    break\n","  if y_test[index] == 0 and y_test_predict_cat[index] == 1:\n","    prRed(X_test.iloc[index,0])\n","    print_stuff(index)\n","    c[0] += 1\n","  #original individual insult (0), classified as other (2)\n","  elif y_test[index] == 0 and y_test_predict_cat[index] == 2:\n","    prGreen(X_test.iloc[index,0])\n","    print_stuff(index)\n","    c[1] += 1\n","  #original group insult (1), classified as individual (0)\n","  elif y_test[index] == 1 and y_test_predict_cat[index] == 0:\n","    prPurple(X_test.iloc[index,0])\n","    print_stuff(index)\n","    c[2] += 1\n","  #original group insult (1), classified as other (2)\n","  elif y_test[index] == 1 and y_test_predict_cat[index] == 2:\n","    prCyan(X_test.iloc[index,0])\n","    print_stuff(index)\n","    c[3] += 1\n","  #original other insult (2), classified as individual (0)\n","  elif y_test[index] == 2 and y_test_predict_cat[index] == 0:\n","    prLighBlue(X_test.iloc[index,0])\n","    print_stuff(index)\n","    c[4] += 1\n","  #original other insult (2), classified as group (1)\n","  elif y_test[index] == 2 and y_test_predict_cat[index] == 1:\n","    prOrange(X_test.iloc[index,0])\n","    print_stuff(index)\n","    c[5] += 1\n"],"execution_count":101,"outputs":[{"output_type":"stream","text":["\u001b[95m @USER //xD Well the suffering she goes through and all the terrible shit she sees ends up making her pretty insane (I think you already seen that from certain things I posted XD) but hey at least she's only insane to bad guys!\u001b[00m\n","preprocessed tweet\n","xd well suffer go terrible shit see end make pretty insane i think already see certain things post xd hey least insane bad guy\n","computed classes:  [1 0 0]\n","original class:  1\n","\u001b[94m @USER @USER @USER Oh and higher unemployment and witch hunts and lynch mobs and antifa communist parades ...you can have all that shit and let Hollywood decide how you feel.\u001b[00m\n","preprocessed tweet\n","oh higher unemployment witch hunt lynch mob antifa communist parade you shit let hollywood decide feel\n","computed classes:  [0 0 1]\n","original class:  2\n","\u001b[95m @USER thanks Joe!!! my sanity was forsaken a looong time ago hahaha\u001b[00m\n","preprocessed tweet\n","thank joe sanity forsake looong time ago hahaha\n","computed classes:  [0 0 2]\n","original class:  1\n","\u001b[33m @USER Yes! The good old days when conservatives got pushed around and bullied by democrats who never gave an inch. The good old days when all conservatives could do was feign outrage and promise to go get them the next time. Yeah, that's what we need. That's the healthy\" libs love!\"\u001b[00m\n","preprocessed tweet\n","yes good old days conservatives get push around bully democrats never give inch good old days conservatives could feign outrage promise go get next time yeah that s need that s healthy libs love\n","computed classes:  [1 1 1]\n","original class:  2\n","\u001b[95m @USER @USER @USER @USER That's just depressing. Good churches are getting hard to find. Few and far between. I know people who belong to churches that espouse gun control and abortion! That's politics - not God! Not Christ!\u001b[00m\n","preprocessed tweet\n","that s depress good church get hard find far between know people belong church espouse gun control abortion that s politics not god not christ\n","computed classes:  [2 0 0]\n","original class:  1\n","\u001b[91m @USER These niggas getting put on list and straight ass 💀 only niggas I seen good was yoshi patchmade jay and a few more rest are ass 💯\u001b[00m\n","preprocessed tweet\n","niggas get put list straight ass niggas see good yoshi patchmade jay rest ass\n","computed classes:  [1 0 1]\n","original class:  0\n","\u001b[94m 4.5 million kids in poverty a screwed up Universal Credit system  Brexitshambles an Economy teetering on the brink  ...the list is endless and the common factor &gt; @USER building a country fit for nothing\u001b[00m\n","preprocessed tweet\n","4 5 million kid poverty screw universal credit system brexitshambles economy teeter brink the list endless common factor gt build country fit nothing\n","computed classes:  [2 1 0]\n","original class:  2\n","\u001b[95m @USER @USER @USER The scary super experienced knowledgeable members of Antifa @USER is no match for! #Sarcasm Serious question is why the left leaders manipulate the unintelligent inexperienced youth groups it’s form of taking advantage Abuse of the unwary weak  URL\u001b[00m\n","preprocessed tweet\n","scary super experience knowledgeable members antifa no match for sarcasm serious question leave leaders manipulate unintelligent inexperienced youth group form take advantage abuse unwary weak\n","computed classes:  [1 0 0]\n","original class:  1\n","\u001b[95m @USER We dont need gun control. We need White Male control....\u001b[00m\n","preprocessed tweet\n","dont need gun control need white male control\n","computed classes:  [0 0 0]\n","original class:  1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w_h_hvTtaWc2","colab_type":"text"},"source":["## Fit on X_train_bow without cross fold"]},{"cell_type":"code","metadata":{"id":"q1dTqJUDCJN1","colab_type":"code","outputId":"bb366bb7-bccd-4e1d-ec6d-02dc4ab7f525","executionInfo":{"status":"ok","timestamp":1573468576238,"user_tz":-330,"elapsed":31337,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = create_model(filter_kernels, dense_outputs, maxlen, vocab_size, nb_filter, cat_output)\n","model.fit( X_train_bow , Y_train_cat , class_weight=  class_weight, batch_size=batch_size, epochs=nb_epoch, validation_split=0.2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["inputs shape:  (?, 1204)\n","conv shape:  (?, 1198, 32)\n","conv max pool shape:  (?, 599, 32)\n","conv1 shape:  (?, 595, 32)\n","conv2 shape:  (?, 593, 32)\n","conv3 shape:  (?, 592, 32)\n","conv4 shape:  (?, 591, 32)\n","conv5 shape:  (?, 590, 32)\n","conv5 m.p shape:  (?, 295, 32)\n","conv5 flatten shape:  (?, ?)\n","Model: \"model_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_6 (InputLayer)         (None, 1204)              0         \n","_________________________________________________________________\n","lambda_6 (Lambda)            (None, 1204, 69)          0         \n","_________________________________________________________________\n","Conv1 (Conv1D)               (None, 1198, 32)          15488     \n","_________________________________________________________________\n","MaxPool1 (MaxPooling1D)      (None, 599, 32)           0         \n","_________________________________________________________________\n","Conv2 (Conv1D)               (None, 595, 32)           5152      \n","_________________________________________________________________\n","Conv3 (Conv1D)               (None, 593, 32)           3104      \n","_________________________________________________________________\n","Conv4 (Conv1D)               (None, 592, 32)           2080      \n","_________________________________________________________________\n","MaxPool4 (MaxPooling1D)      (None, 295, 32)           0         \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 9440)              0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 1024)              9667584   \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 1024)              0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 1024)              0         \n","_________________________________________________________________\n","output (Dense)               (None, 3)                 3075      \n","=================================================================\n","Total params: 10,746,083\n","Trainable params: 10,746,083\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Train on 2170 samples, validate on 543 samples\n","Epoch 1/20\n","2170/2170 [==============================] - 3s 1ms/step - loss: 2.0148 - acc: 0.4097 - f1_m: 0.0074 - precision_m: 0.0531 - recall_m: 0.0041 - val_loss: 2.1494 - val_acc: 0.4641 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n","Epoch 2/20\n","2170/2170 [==============================] - 1s 657us/step - loss: 1.9921 - acc: 0.4470 - f1_m: 0.0991 - precision_m: 0.2069 - recall_m: 0.0673 - val_loss: 2.0988 - val_acc: 0.5617 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n","Epoch 3/20\n","2170/2170 [==============================] - 1s 657us/step - loss: 1.9621 - acc: 0.5281 - f1_m: 0.1511 - precision_m: 0.4586 - recall_m: 0.0977 - val_loss: 2.1865 - val_acc: 0.5451 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n","Epoch 4/20\n","2170/2170 [==============================] - 1s 646us/step - loss: 1.9297 - acc: 0.5396 - f1_m: 0.2144 - precision_m: 0.5262 - recall_m: 0.1479 - val_loss: 2.0807 - val_acc: 0.4144 - val_f1_m: 0.2029 - val_precision_m: 0.5911 - val_recall_m: 0.1234\n","Epoch 5/20\n","2170/2170 [==============================] - 1s 648us/step - loss: 1.8676 - acc: 0.6304 - f1_m: 0.3025 - precision_m: 0.6910 - recall_m: 0.2152 - val_loss: 2.2057 - val_acc: 0.6151 - val_f1_m: 0.5729 - val_precision_m: 0.7025 - val_recall_m: 0.4843\n","Epoch 6/20\n","2170/2170 [==============================] - 1s 647us/step - loss: 1.7894 - acc: 0.6318 - f1_m: 0.5285 - precision_m: 0.7900 - recall_m: 0.4060 - val_loss: 2.0689 - val_acc: 0.5654 - val_f1_m: 0.4863 - val_precision_m: 0.7259 - val_recall_m: 0.3665\n","Epoch 7/20\n","2170/2170 [==============================] - 1s 632us/step - loss: 1.7224 - acc: 0.6300 - f1_m: 0.5952 - precision_m: 0.8027 - recall_m: 0.4783 - val_loss: 2.0615 - val_acc: 0.5562 - val_f1_m: 0.4654 - val_precision_m: 0.7029 - val_recall_m: 0.3499\n","Epoch 8/20\n","2170/2170 [==============================] - 1s 629us/step - loss: 1.6306 - acc: 0.6590 - f1_m: 0.6263 - precision_m: 0.7689 - recall_m: 0.5336 - val_loss: 2.2833 - val_acc: 0.5654 - val_f1_m: 0.5455 - val_precision_m: 0.6952 - val_recall_m: 0.4494\n","Epoch 9/20\n","2170/2170 [==============================] - 1s 631us/step - loss: 1.5705 - acc: 0.6613 - f1_m: 0.6543 - precision_m: 0.7874 - recall_m: 0.5618 - val_loss: 2.2821 - val_acc: 0.5414 - val_f1_m: 0.5186 - val_precision_m: 0.6412 - val_recall_m: 0.4365\n","Epoch 10/20\n","2170/2170 [==============================] - 1s 635us/step - loss: 1.4088 - acc: 0.7009 - f1_m: 0.6899 - precision_m: 0.7670 - recall_m: 0.6290 - val_loss: 2.5919 - val_acc: 0.5912 - val_f1_m: 0.5812 - val_precision_m: 0.6674 - val_recall_m: 0.5157\n","Epoch 11/20\n","2170/2170 [==============================] - 1s 637us/step - loss: 1.3110 - acc: 0.7180 - f1_m: 0.7148 - precision_m: 0.7685 - recall_m: 0.6696 - val_loss: 2.5805 - val_acc: 0.4309 - val_f1_m: 0.4152 - val_precision_m: 0.4574 - val_recall_m: 0.3812\n","Epoch 12/20\n","2170/2170 [==============================] - 1s 638us/step - loss: 1.2658 - acc: 0.7046 - f1_m: 0.6984 - precision_m: 0.7497 - recall_m: 0.6548 - val_loss: 3.1619 - val_acc: 0.4954 - val_f1_m: 0.4861 - val_precision_m: 0.5131 - val_recall_m: 0.4622\n","Epoch 13/20\n","2170/2170 [==============================] - 1s 645us/step - loss: 0.9909 - acc: 0.7903 - f1_m: 0.7937 - precision_m: 0.8157 - recall_m: 0.7733 - val_loss: 3.3236 - val_acc: 0.5414 - val_f1_m: 0.5300 - val_precision_m: 0.5541 - val_recall_m: 0.5083\n","Epoch 14/20\n","2170/2170 [==============================] - 1s 631us/step - loss: 0.9151 - acc: 0.8189 - f1_m: 0.8189 - precision_m: 0.8364 - recall_m: 0.8023 - val_loss: 3.5838 - val_acc: 0.5193 - val_f1_m: 0.5088 - val_precision_m: 0.5254 - val_recall_m: 0.4936\n","Epoch 15/20\n","2170/2170 [==============================] - 1s 632us/step - loss: 0.8434 - acc: 0.8263 - f1_m: 0.8253 - precision_m: 0.8444 - recall_m: 0.8074 - val_loss: 3.9494 - val_acc: 0.5617 - val_f1_m: 0.5650 - val_precision_m: 0.5802 - val_recall_m: 0.5506\n","Epoch 16/20\n","2170/2170 [==============================] - 1s 637us/step - loss: 0.7171 - acc: 0.8641 - f1_m: 0.8627 - precision_m: 0.8753 - recall_m: 0.8507 - val_loss: 4.5192 - val_acc: 0.5433 - val_f1_m: 0.5378 - val_precision_m: 0.5514 - val_recall_m: 0.5249\n","Epoch 17/20\n","2170/2170 [==============================] - 1s 621us/step - loss: 0.5745 - acc: 0.8912 - f1_m: 0.8909 - precision_m: 0.8986 - recall_m: 0.8834 - val_loss: 4.8591 - val_acc: 0.5157 - val_f1_m: 0.5119 - val_precision_m: 0.5277 - val_recall_m: 0.4972\n","Epoch 18/20\n","2170/2170 [==============================] - 1s 626us/step - loss: 0.5540 - acc: 0.8839 - f1_m: 0.8841 - precision_m: 0.8920 - recall_m: 0.8765 - val_loss: 4.3365 - val_acc: 0.5120 - val_f1_m: 0.5084 - val_precision_m: 0.5182 - val_recall_m: 0.4991\n","Epoch 19/20\n","2170/2170 [==============================] - 1s 640us/step - loss: 0.7038 - acc: 0.8493 - f1_m: 0.8471 - precision_m: 0.8592 - recall_m: 0.8355 - val_loss: 4.6128 - val_acc: 0.5635 - val_f1_m: 0.5675 - val_precision_m: 0.5774 - val_recall_m: 0.5580\n","Epoch 20/20\n","2170/2170 [==============================] - 1s 634us/step - loss: 0.5264 - acc: 0.9028 - f1_m: 0.9003 - precision_m: 0.9112 - recall_m: 0.8899 - val_loss: 5.5844 - val_acc: 0.5433 - val_f1_m: 0.5352 - val_precision_m: 0.5460 - val_recall_m: 0.5249\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fec3936c160>"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"markdown","metadata":{"id":"NPqkmfeMaDX-","colab_type":"text"},"source":["Predicting on X_test_bow"]},{"cell_type":"code","metadata":{"id":"G0yqOcw-BkDz","colab_type":"code","colab":{}},"source":["y_test_predict = model.predict(X_test_bow)\n","y_test_predict_cat = y_test_predict.argmax(axis = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8H-z2Nv3etP","colab_type":"code","outputId":"8e40109d-63ee-4213-b730-a93acf3471f6","executionInfo":{"status":"ok","timestamp":1573468578384,"user_tz":-330,"elapsed":2099,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":514}},"source":["print(classification_report(Y_test , y_test_predict_cat))\n","results = confusion_matrix(Y_test , y_test_predict_cat)\n","\n","%matplotlib inline\n","plt.figure(figsize = (5,5))\n","ax = sns.heatmap(results, cmap=\"Blues\", annot=True,annot_kws={\"size\": 14},fmt='g')\n","bottom, top = ax.get_ylim()\n","ax.set_ylim(bottom + 0.5, top - 0.5)\n","plt.ylabel('True Class')\n","plt.xlabel('Predicted Class')\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.72      0.67      0.69       722\n","           1       0.47      0.45      0.46       322\n","           2       0.11      0.18      0.14       119\n","\n","    accuracy                           0.56      1163\n","   macro avg       0.43      0.43      0.43      1163\n","weighted avg       0.59      0.56      0.57      1163\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUIAAAFACAYAAADJZXWXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 360x360 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"B5gR-MlH1JFC","colab_type":"code","outputId":"d9347b7a-10d2-4b66-d340-1c0748631a99","executionInfo":{"status":"ok","timestamp":1573468578386,"user_tz":-330,"elapsed":2072,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["f1_score(Y_test, final_prediction, average='macro')  "],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4691418593044034"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-70igbqVsf-A"},"source":["### Misclassified examples for without k fold"]},{"cell_type":"code","metadata":{"id":"yl6cb8_8ynqL","colab_type":"code","colab":{}},"source":["y_test_predict_cat = final_prediction\n","y_test = np.asarray(Y_test)\n","misclassified = np.where(y_test != y_test_predict_cat)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pmbXMtboZWQD"},"source":["Red: original individual insult (0), classified as group (1)<br>\n","Green: original individual insult (0), classified as other (2)<br>\n","Purple: original group insult (1), classified as individual (0) <br>\n","Cyan: original group insult (1), classified as other (2)<br>\n","Light Blue: original other insult (2), classified as individual (0) <br>\n","Orange: original other insult (2), classified as group (1)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"e_EvGPmIZWQH","outputId":"e585f02e-d546-4303-d131-6c201f352822","executionInfo":{"status":"ok","timestamp":1573452797077,"user_tz":-330,"elapsed":1292,"user":{"displayName":"Shruti Chandra","photoUrl":"","userId":"13968414218437022561"}},"colab":{"base_uri":"https://localhost:8080/","height":819}},"source":["#IND=0, GRP=1 , OTH= 2\n","c = [0] * 6\n","limit = 5\n","for index in misclassified[0]:\n","  #original individual insult (0), classified as group (1)\n","  if limit in c:\n","    break\n","  if y_test[index] == 0 and y_test_predict_cat[index] == 1:\n","    prRed(X_test.iloc[index,0])\n","    print_stuff(index)\n","    c[0] += 1\n","  #original individual insult (0), classified as other (2)\n","  elif y_test[index] == 0 and y_test_predict_cat[index] == 2:\n","    prGreen(X_test.iloc[index,0])\n","    print_stuff(index)\n","    c[1] += 1\n","  #original group insult (1), classified as individual (0)\n","  elif y_test[index] == 1 and y_test_predict_cat[index] == 0:\n","    prPurple(X_test.iloc[index,0])\n","    print_stuff(index)\n","    c[2] += 1\n","  #original group insult (1), classified as other (2)\n","  elif y_test[index] == 1 and y_test_predict_cat[index] == 2:\n","    prCyan(X_test.iloc[index,0])\n","    print_stuff(index)\n","    c[3] += 1\n","  #original other insult (2), classified as individual (0)\n","  elif y_test[index] == 2 and y_test_predict_cat[index] == 0:\n","    prLighBlue(X_test.iloc[index,0])\n","    print_stuff(index)\n","    c[4] += 1\n","  #original other insult (2), classified as group (1)\n","  elif y_test[index] == 2 and y_test_predict_cat[index] == 1:\n","    prOrange(X_test.iloc[index,0])\n","    print_stuff(index)\n","    c[5] += 1\n"],"execution_count":102,"outputs":[{"output_type":"stream","text":["\u001b[95m @USER //xD Well the suffering she goes through and all the terrible shit she sees ends up making her pretty insane (I think you already seen that from certain things I posted XD) but hey at least she's only insane to bad guys!\u001b[00m\n","preprocessed tweet\n","xd well suffer go terrible shit see end make pretty insane i think already see certain things post xd hey least insane bad guy\n","computed classes:  [1 0 0]\n","original class:  1\n","\u001b[94m @USER @USER @USER Oh and higher unemployment and witch hunts and lynch mobs and antifa communist parades ...you can have all that shit and let Hollywood decide how you feel.\u001b[00m\n","preprocessed tweet\n","oh higher unemployment witch hunt lynch mob antifa communist parade you shit let hollywood decide feel\n","computed classes:  [0 0 1]\n","original class:  2\n","\u001b[95m @USER thanks Joe!!! my sanity was forsaken a looong time ago hahaha\u001b[00m\n","preprocessed tweet\n","thank joe sanity forsake looong time ago hahaha\n","computed classes:  [0 0 2]\n","original class:  1\n","\u001b[33m @USER Yes! The good old days when conservatives got pushed around and bullied by democrats who never gave an inch. The good old days when all conservatives could do was feign outrage and promise to go get them the next time. Yeah, that's what we need. That's the healthy\" libs love!\"\u001b[00m\n","preprocessed tweet\n","yes good old days conservatives get push around bully democrats never give inch good old days conservatives could feign outrage promise go get next time yeah that s need that s healthy libs love\n","computed classes:  [1 1 1]\n","original class:  2\n","\u001b[95m @USER @USER @USER @USER That's just depressing. Good churches are getting hard to find. Few and far between. I know people who belong to churches that espouse gun control and abortion! That's politics - not God! Not Christ!\u001b[00m\n","preprocessed tweet\n","that s depress good church get hard find far between know people belong church espouse gun control abortion that s politics not god not christ\n","computed classes:  [2 0 0]\n","original class:  1\n","\u001b[91m @USER These niggas getting put on list and straight ass 💀 only niggas I seen good was yoshi patchmade jay and a few more rest are ass 💯\u001b[00m\n","preprocessed tweet\n","niggas get put list straight ass niggas see good yoshi patchmade jay rest ass\n","computed classes:  [1 0 1]\n","original class:  0\n","\u001b[94m 4.5 million kids in poverty a screwed up Universal Credit system  Brexitshambles an Economy teetering on the brink  ...the list is endless and the common factor &gt; @USER building a country fit for nothing\u001b[00m\n","preprocessed tweet\n","4 5 million kid poverty screw universal credit system brexitshambles economy teeter brink the list endless common factor gt build country fit nothing\n","computed classes:  [2 1 0]\n","original class:  2\n","\u001b[95m @USER @USER @USER The scary super experienced knowledgeable members of Antifa @USER is no match for! #Sarcasm Serious question is why the left leaders manipulate the unintelligent inexperienced youth groups it’s form of taking advantage Abuse of the unwary weak  URL\u001b[00m\n","preprocessed tweet\n","scary super experience knowledgeable members antifa no match for sarcasm serious question leave leaders manipulate unintelligent inexperienced youth group form take advantage abuse unwary weak\n","computed classes:  [1 0 0]\n","original class:  1\n","\u001b[95m @USER We dont need gun control. We need White Male control....\u001b[00m\n","preprocessed tweet\n","dont need gun control need white male control\n","computed classes:  [0 0 0]\n","original class:  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OYSo0iuDB4oN","colab_type":"code","outputId":"613f339a-3bfd-4935-c089-8a0fe33c7a53","executionInfo":{"status":"ok","timestamp":1573468579587,"user_tz":-330,"elapsed":3221,"user":{"displayName":"Archit Kumar","photoUrl":"","userId":"03572085286762964127"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# serialize model to YAML\n","model_yaml = model.to_yaml()\n","with open(root_path + \"/CNN/model_C.yaml\", \"w\") as yaml_file:\n","    yaml_file.write(model_yaml)\n","# serialize weights to HDF5\n","model.save_weights(root_path + \"/CNN/model_C.h5\")\n","print(\"Saved model to disk\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Saved model to disk\n"],"name":"stdout"}]}]}